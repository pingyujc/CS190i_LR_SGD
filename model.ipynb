{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "14678bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read file into panda df\n",
    "def pandas_reader(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.set_index('id')\n",
    "    return df\n",
    "def convert_numpy(train):\n",
    "    # x be all the words\n",
    "    train_x = train[list(train.keys())[:-1]]\n",
    "    # let y be the label of trainging set\n",
    "    train_y = train['label']\n",
    "    np_train_x = train_x.to_numpy() \n",
    "    np_train_y = train_y.to_numpy()\n",
    "    return np_train_x, np_train_y\n",
    "\n",
    "    return np_train_x, np_train_y\n",
    "def export_csv(test_noans, out_label):\n",
    "    # put labels into test with noans first\n",
    "    test_noans[\"label\"] = out_label\n",
    "\n",
    "    # get id and label col\n",
    "    test_answer = test_noans[\"label\"]\n",
    "\n",
    "    # export to csv\n",
    "    test_answer.to_csv(\"test_answer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ad15299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas_reader(\"train.csv\")\n",
    "x, y = convert_numpy(train)\n",
    "test = pandas_reader(\"test_noans.csv\")\n",
    "test_x = test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9dbf7524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 ... 0 0 0]\n",
      " [1 0 2 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 3 0 ... 0 0 0]\n",
      " [1 5 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]] 3000\n",
      "[0 0 0 ... 0 0 1] 3000\n"
     ]
    }
   ],
   "source": [
    "print(x, len(x))\n",
    "print(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a28616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nInitialize the weight vector w and the learning rate α; \\nwhile objective function not converged do:\\n    Randomly shuffle the order of the examples in the training set;\\n    for each example in the training set do:\\n    w = w + α((y − p)w − 2λw );\\n    end \\nend\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Initialize the weight vector w and the learning rate α; \n",
    "while objective function not converged do:\n",
    "    Randomly shuffle the order of the examples in the training set;\n",
    "    for each example in the training set do:\n",
    "    w = w + α((y − p)x − 2λw );\n",
    "    end \n",
    "end\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f3b16e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will calculate p using dot product\n",
    "# p = 1 / (1 + e^ -(x*w))\n",
    "def getp(x, w):\n",
    "    z = np.dot(x, w)\n",
    "    p = 1 / (1 + np.exp(-z))\n",
    "    return p\n",
    "# returns λ||w||2\n",
    "def getNorm(lamb, w):\n",
    "    norm = 0\n",
    "    for el in w:\n",
    "        norm += el**2\n",
    "    norm = np.sqrt(norm)\n",
    "    norm = lamb* norm\n",
    "    return norm\n",
    "\n",
    "# w is the initilized weight vector\n",
    "# a is the learning rate, lamb is lambda.\n",
    "# we should output the converged weight vector\n",
    "def SGD(x, y, w, a, lamb):\n",
    "    \n",
    "    # calculte LCL based on the current weight vector\n",
    "    # LCL = sum of (yi*log p + (1-yi)* log(1-p))\n",
    "    # for every i, yi is the label, and p should be different\n",
    "    LCL = 0\n",
    "    new = 0\n",
    "    prev = 0\n",
    "    for i in range(len(x)):\n",
    "        p = getp(x[i], w) # the p for this data\n",
    "        LCL += (y[i]*np.log(p) + (1-y[i]) * np.log(1-p)) # sum up the LCL\n",
    "    \n",
    "    norm = getNorm(lamb, w)\n",
    "    new = LCL - norm\n",
    "    \n",
    "    # stop the while loop when further iterations won't change the weight anymore\n",
    "    # checking if the change in LCL − λ||w||2 is less than a small value 1.0 × 10−3 or 1.0 × 10−4\n",
    "    # ||w||2 = sqrt(w1^2 + w2^2 + w3^2 + ... wn^2)\n",
    "    #  while \"objective function do not converge\":\n",
    "    epoch = 0\n",
    "\n",
    "    while np.abs(new - prev) > 10 ** -3 :\n",
    "        print(np.abs(new - prev), p, y[-1])\n",
    "        epoch += 1\n",
    "        \n",
    "        print(\"epoch:\", epoch)\n",
    "#         if epoch > 150:\n",
    "#             break\n",
    "            \n",
    "        # shuffle the training data\n",
    "        # Get a random permutation of indices\n",
    "        indices = np.random.permutation(len(x))\n",
    "\n",
    "        # Shuffle x and y using the same permutation\n",
    "        x = x[indices]\n",
    "        y = y[indices]\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            p = getp(x[i], w) # current p value\n",
    "            # w = w + α((y − p)x − 2λw );\n",
    "            res = [element * 2 * lamb for element in w] # 2 *lamb * w\n",
    "\n",
    "            w = w + a*((y[i] - p)*x[i] - res)\n",
    "        \n",
    "        prev = new # record the previous LCL - norm\n",
    "        LCL = 0 # recalculate new LCL here\n",
    "        for i in range(len(x)):\n",
    "            p = getp(x[i], w) # the p for this data\n",
    "            LCL += (y[i]*np.log(p) + (1-y[i]) * np.log(1-p)) # sum up the LCL\n",
    "        norm = getNorm(lamb, w)\n",
    "        new = LCL - norm\n",
    "        # dacay learning rate\n",
    "        a = 0.975 * a\n",
    "\n",
    "    # after the while loop ends, we return the optimized weight\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "db9ad428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for 10 fold CV we need to train the model on 10 different data set, each one with a 10% held out training data\n",
    "# after training, we use the held out data to test. And we will take the average of all the accuracy.\n",
    "# w is the initilized weight vector\n",
    "# a is the learning rate, lamb is lambda.\n",
    "# we should output the converged weight vector\n",
    "def SGD_test(x, y, w, a, lamb, held_x, held_y):\n",
    "    \n",
    "    # calculte LCL based on the current weight vector\n",
    "    # LCL = sum of (yi*log p + (1-yi)* log(1-p))\n",
    "    # for every i, yi is the label, and p should be different\n",
    "    LCL = 0\n",
    "    new = 0\n",
    "    prev = 0\n",
    "    for i in range(len(x)):\n",
    "        p = getp(x[i], w) # the p for this data\n",
    "        LCL += (y[i]*np.log(p) + (1-y[i]) * np.log(1-p)) # sum up the LCL\n",
    "    \n",
    "    norm = getNorm(lamb, w)\n",
    "    new = LCL - norm\n",
    "    \n",
    "    # stop the while loop when further iterations won't change the weight anymore\n",
    "    # checking if the change in LCL − λ||w||2 is less than a small value 1.0 × 10−3 or 1.0 × 10−4\n",
    "    # ||w||2 = sqrt(w1^2 + w2^2 + w3^2 + ... wn^2)\n",
    "    #  while \"objective function do not converge\":\n",
    "    epoch = 0\n",
    "    max_acc = 0\n",
    "    max_epoch = 0\n",
    "    while np.abs(new - prev) > 10 ** -3 :\n",
    "        print(np.abs(new - prev), p, y[-1])\n",
    "        epoch += 1\n",
    "        \n",
    "        print(\"epoch:\", epoch)\n",
    "#         if epoch > 100:\n",
    "#             break\n",
    "            \n",
    "        # shuffle the training data\n",
    "        # Get a random permutation of indices\n",
    "        indices = np.random.permutation(len(x))\n",
    "\n",
    "        # Shuffle x and y using the same permutation\n",
    "        x = x[indices]\n",
    "        y = y[indices]\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            p = getp(x[i], w) # current p value\n",
    "            # w = w + α((y − p)x − 2λw );\n",
    "            res = [element * 2 * lamb for element in w] # 2 *lamb * w\n",
    "\n",
    "            w = w + a*((y[i] - p)*x[i] - res)\n",
    "        \n",
    "        prev = new # record the previous LCL - norm\n",
    "        LCL = 0 # recalculate new LCL here\n",
    "        for i in range(len(x)):\n",
    "            p = getp(x[i], w) # the p for this data\n",
    "            LCL += (y[i]*np.log(p) + (1-y[i]) * np.log(1-p)) # sum up the LCL\n",
    "        norm = getNorm(lamb, w)\n",
    "        new = LCL - norm\n",
    "        # dacay learning rate\n",
    "        a = 0.98 * a\n",
    "        \n",
    "        # test the accuracy rate\n",
    "        correct = 0\n",
    "        total = len(held_x)\n",
    "        # loop through these \n",
    "        for j in range(len(held_x)):\n",
    "            pj = getp(held_x[j], w)\n",
    "            p1 = pj # probability of label = 1\n",
    "            p0 = 1 - pj # probability of label = 0\n",
    "            if p1 > p0 :\n",
    "                # we predict 1\n",
    "                if y[j] == 1:\n",
    "                    correct += 1 \n",
    "            else:\n",
    "                if y[j] == 0:\n",
    "                    correct += 1\n",
    "        accuracy = correct / total\n",
    "        print(\"accuracy:\", accuracy)\n",
    "        if accuracy > max_acc:\n",
    "            max_acc = accuracy\n",
    "            max_epoch = epoch\n",
    "    # after the while loop ends, we return the optimized weight\n",
    "    \n",
    "    print(\"max accuracy:\", max_acc)\n",
    "    print(\"epoch peaked at:\", max_epoch)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3085c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "A = [1,2,3,4]\n",
    "print(A[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42998c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, test_x):\n",
    "    # compute the labels using the weight vectors we have\n",
    "    output = []\n",
    "    for j in range(len(test_x)):\n",
    "        p = getp(test_x[j], w)\n",
    "        p1 = p # probability of label = 1\n",
    "        p0 = 1 - p # probability of label = 0\n",
    "        if p1 > p0 :\n",
    "            output.append(1)\n",
    "            \n",
    "        else:\n",
    "            output.append(0)\n",
    "        \n",
    "    # print(output)\n",
    "\n",
    "    export_csv(test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4443f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variable used for running the model\n",
    "w = [0] * len(x[0])\n",
    "a = 0.1 # our choice of learning rate\n",
    "lamb = 0.0002 # our choice of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c6be3c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "2900 2900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hold out some data to test the accuracy\n",
    "held_x = x[0:100]\n",
    "held_y = y[0:100]\n",
    "x = x[100:]\n",
    "y = y[100:]\n",
    "\n",
    "print(len(held_x), len(held_y))\n",
    "print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "26ee0382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "236dbe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2079.4415416797233 0.5 1\n",
      "epoch: 1\n",
      "511.1336707774801 0.04707746760443521 0\n",
      "epoch: 2\n",
      "240.5169019041291 0.2898746776143355 0\n",
      "epoch: 3\n",
      "155.0368171771063 0.908151272510554 1\n",
      "epoch: 4\n",
      "14.836873056600552 0.7501693028256219 1\n",
      "epoch: 5\n",
      "168.38410704956414 0.08564085114093514 0\n",
      "epoch: 6\n",
      "53.36729617588696 0.7547551648399894 1\n",
      "epoch: 7\n",
      "49.58841247568262 0.8796911174267457 1\n",
      "epoch: 8\n",
      "18.49798874079022 0.8607599294305872 1\n",
      "epoch: 9\n",
      "10.011444613871276 0.34385395266145147 0\n",
      "epoch: 10\n",
      "56.0693766466884 0.8467271556581496 1\n",
      "epoch: 11\n",
      "26.663990157714352 0.9741129938392393 1\n",
      "epoch: 12\n",
      "7.564855308977599 0.14255143312397703 0\n",
      "epoch: 13\n",
      "15.07630049106126 0.08482156102765068 0\n",
      "epoch: 14\n",
      "50.72738207978841 0.8719025625029153 1\n",
      "epoch: 15\n",
      "228.68358380096026 0.015366765363063146 0\n",
      "epoch: 16\n",
      "217.68214659441833 0.011366236478713935 0\n",
      "epoch: 17\n",
      "17.845273736318518 0.5078783178372178 1\n",
      "epoch: 18\n",
      "13.344816971928935 0.8987324932212856 1\n",
      "epoch: 19\n",
      "1.830563738549131 0.5086383738781161 1\n",
      "epoch: 20\n",
      "8.267546115583968 0.9203994809533443 1\n",
      "epoch: 21\n",
      "65.24107169514389 0.7536001608444816 1\n",
      "epoch: 22\n",
      "27.46379338293775 0.1061276910660016 0\n",
      "epoch: 23\n",
      "30.87252069501801 0.9303212971540865 1\n",
      "epoch: 24\n",
      "22.51361692708531 0.17490654715371454 0\n",
      "epoch: 25\n",
      "18.80111481877134 0.2430729132846678 0\n",
      "epoch: 26\n",
      "16.586068391861545 0.7595741087569529 1\n",
      "epoch: 27\n",
      "23.870841466484876 0.8557441800546304 1\n",
      "epoch: 28\n",
      "23.21299725558606 0.390387935762936 0\n",
      "epoch: 29\n",
      "4.635070399775827 0.8441231126489185 1\n",
      "epoch: 30\n",
      "31.05214129813635 0.20850648562895913 0\n",
      "epoch: 31\n",
      "5.659869938185238 0.9651795286222347 1\n",
      "epoch: 32\n",
      "26.81693112498806 0.8730982757550245 1\n",
      "epoch: 33\n",
      "13.289353388158816 0.8158153786049297 1\n",
      "epoch: 34\n",
      "3.4834428772470574 0.18119424490936892 0\n",
      "epoch: 35\n",
      "10.759877906505153 0.2272526979979754 0\n",
      "epoch: 36\n",
      "27.03429495386922 0.9970262078461142 1\n",
      "epoch: 37\n",
      "21.2165748122668 0.8554040805460238 1\n",
      "epoch: 38\n",
      "20.359347359045955 0.8694926005213565 1\n",
      "epoch: 39\n",
      "2.880806888656707 0.7682560992514577 1\n",
      "epoch: 40\n",
      "26.0154681222034 0.7106325567897303 1\n",
      "epoch: 41\n",
      "2.615847712950199 0.1247556273952105 0\n",
      "epoch: 42\n",
      "64.97562019559132 0.14331975734606797 0\n",
      "epoch: 43\n",
      "68.55951477272288 0.8493632808981276 1\n",
      "epoch: 44\n",
      "17.819835627203474 0.0791627782535966 0\n",
      "epoch: 45\n",
      "3.631790727025418 0.45574584811697777 0\n",
      "epoch: 46\n",
      "2.497789056618558 0.0044450141813360934 0\n",
      "epoch: 47\n",
      "5.4231840703024545 0.05527867534694931 0\n",
      "epoch: 48\n",
      "6.73146102051021 0.18029056791981163 0\n",
      "epoch: 49\n",
      "5.526580978691982 0.7886334925480036 1\n",
      "epoch: 50\n",
      "0.6046836071247981 0.8117644977681167 1\n",
      "epoch: 51\n",
      "7.437253351528852 0.16516569417405305 0\n",
      "epoch: 52\n",
      "1.2909641815369923 0.7982583362674895 1\n",
      "epoch: 53\n",
      "2.221608250237864 0.8096677827523218 1\n",
      "epoch: 54\n",
      "7.676901621412981 0.23281889947358847 0\n",
      "epoch: 55\n",
      "5.316740127008302 0.8550885216215597 1\n",
      "epoch: 56\n",
      "3.2936429984902134 0.9303176527950485 1\n",
      "epoch: 57\n",
      "5.131106832971568 0.19860262887374827 0\n",
      "epoch: 58\n",
      "12.512835603542271 0.6973590407403228 1\n",
      "epoch: 59\n",
      "0.40271759126380857 0.8419331977414279 1\n",
      "epoch: 60\n",
      "1.4540098756342559 0.7872406892317505 1\n",
      "epoch: 61\n",
      "16.662178578436396 0.72992765548788 1\n",
      "epoch: 62\n",
      "5.98961247470811 0.4782919051195098 0\n",
      "epoch: 63\n",
      "0.7684092087463341 0.7671737257506617 1\n",
      "epoch: 64\n",
      "5.031405754871912 0.44755920577524555 1\n",
      "epoch: 65\n",
      "18.41116902945737 0.15976378717561862 0\n",
      "epoch: 66\n",
      "10.028453619553375 0.9437123265260485 1\n",
      "epoch: 67\n",
      "1.2532566648873171 0.796530623661343 1\n",
      "epoch: 68\n",
      "7.348524644766826 0.1509648483943326 0\n",
      "epoch: 69\n",
      "3.0800556295765773 0.021051230469191978 0\n",
      "epoch: 70\n",
      "0.16288334797241077 0.9608526371830051 1\n",
      "epoch: 71\n",
      "5.42172599628941 0.6227325482099624 1\n",
      "epoch: 72\n",
      "16.838374213992893 0.13374954245906626 0\n",
      "epoch: 73\n",
      "14.16900197454936 0.13427588309774988 0\n",
      "epoch: 74\n",
      "2.0985856324740553 0.5504259680706377 0\n",
      "epoch: 75\n",
      "1.6410351620786514 0.614783847804402 1\n",
      "epoch: 76\n",
      "0.847329093365147 0.9359557854947081 1\n",
      "epoch: 77\n",
      "1.2637022561165168 0.8513850992620775 1\n",
      "epoch: 78\n",
      "1.113299513277866 0.7244366602280404 1\n",
      "epoch: 79\n",
      "0.20034795996150478 0.8478824512301681 1\n",
      "epoch: 80\n",
      "3.0918328492066394 0.27474420186474974 0\n",
      "epoch: 81\n",
      "3.564709620752069 0.9644001250310532 1\n",
      "epoch: 82\n",
      "4.454247599043583 0.5880236666726167 0\n",
      "epoch: 83\n",
      "7.407506416656588 0.9605266797530887 1\n",
      "epoch: 84\n",
      "6.067018009546359 0.7052352381540181 1\n",
      "epoch: 85\n",
      "3.9691462794767176 0.7541189725005913 1\n",
      "epoch: 86\n",
      "6.414973583141318 0.9744818124593433 1\n",
      "epoch: 87\n",
      "2.996213486547731 0.17864353745273487 0\n",
      "epoch: 88\n",
      "0.5217826701597232 0.2179835999247297 0\n",
      "epoch: 89\n",
      "6.314483075186899 0.499830487175853 1\n",
      "epoch: 90\n",
      "5.355711466974299 0.9530898563653123 1\n",
      "epoch: 91\n",
      "1.8093666306727982 0.18077253051710515 0\n",
      "epoch: 92\n",
      "3.7238219900500553 0.5 0\n",
      "epoch: 93\n",
      "6.323052042446648 0.7727317444710542 1\n",
      "epoch: 94\n",
      "1.3039102148121628 0.28567487179769585 0\n",
      "epoch: 95\n",
      "5.797812989088811 0.13626933319628096 0\n",
      "epoch: 96\n",
      "6.64596195911929 0.13050797304909725 0\n",
      "epoch: 97\n",
      "0.6165203969242157 0.28629047062034013 0\n",
      "epoch: 98\n",
      "2.2652208468695108 0.7018572845229833 1\n",
      "epoch: 99\n",
      "2.1035353616373413 0.6964662291412795 1\n",
      "epoch: 100\n",
      "0.8886432371052706 0.5520318008857008 1\n",
      "epoch: 101\n",
      "7.538478924094534 0.6035306758690652 1\n",
      "epoch: 102\n",
      "5.587653523636618 0.9177300422888514 1\n",
      "epoch: 103\n",
      "11.926510769298147 0.8514951827816652 1\n",
      "epoch: 104\n",
      "1.2710321340431392 0.8650982223951805 1\n",
      "epoch: 105\n",
      "2.0292151505600486 0.1356494646076247 0\n",
      "epoch: 106\n",
      "0.33911106196285346 0.14301039994464262 0\n",
      "epoch: 107\n",
      "2.95072101685696 0.08634144158264347 0\n",
      "epoch: 108\n",
      "0.2540474763814018 0.6854403264495694 1\n",
      "epoch: 109\n",
      "2.719633821511593 0.8635642969704195 1\n",
      "epoch: 110\n",
      "1.8003798614209927 0.20306177473514803 0\n",
      "epoch: 111\n",
      "0.5801320988276757 0.4853785611774413 0\n",
      "epoch: 112\n",
      "1.6113952670083336 0.007875091891021297 0\n",
      "epoch: 113\n",
      "5.702557630499427 0.26946494294887435 0\n",
      "epoch: 114\n",
      "6.2402088462815755 0.43282347133870847 0\n",
      "epoch: 115\n",
      "2.4822046914657676 0.9664130107769324 1\n",
      "epoch: 116\n",
      "2.3562823216342395 0.0776524084216185 0\n",
      "epoch: 117\n",
      "0.04413145704029375 0.7021866648340324 1\n",
      "epoch: 118\n",
      "0.7476138927597731 0.16523988108358922 0\n",
      "epoch: 119\n",
      "0.3795098427821131 0.904199197846165 1\n",
      "epoch: 120\n",
      "0.1854846236906269 0.8680108679878917 1\n",
      "epoch: 121\n",
      "2.352343688023666 0.9532090984563405 1\n",
      "epoch: 122\n",
      "2.483531408863314 0.783817268548126 1\n",
      "epoch: 123\n",
      "0.3775084153684247 0.061258592216925825 0\n",
      "epoch: 124\n",
      "0.7199495520193295 0.15155550387940392 0\n",
      "epoch: 125\n",
      "0.8789760202768093 0.9368142130971792 1\n",
      "epoch: 126\n",
      "0.0812489412545574 0.04455115582023184 0\n",
      "epoch: 127\n",
      "1.9534490256281742 0.8538167517611737 1\n",
      "epoch: 128\n",
      "1.5725251295976932 0.06321700520958824 0\n",
      "epoch: 129\n",
      "0.28200696844169215 0.14570476768477028 0\n",
      "epoch: 130\n",
      "0.4083318356142627 0.6575395409456802 1\n",
      "epoch: 131\n",
      "0.10504477400752421 0.7097813770261481 1\n",
      "epoch: 132\n",
      "1.2555159432444043 0.9472383420595686 1\n",
      "epoch: 133\n",
      "0.6079078152708917 0.7876697492801944 1\n",
      "epoch: 134\n",
      "0.7269026836819421 0.9485259952305898 1\n",
      "epoch: 135\n",
      "1.4457289305961467 0.9181429745455176 1\n",
      "epoch: 136\n",
      "1.4326492878852832 0.021267441018885738 0\n",
      "epoch: 137\n",
      "0.25300216264201936 0.16126333207477397 0\n",
      "epoch: 138\n",
      "0.39904020998062606 0.5820540023583087 1\n",
      "epoch: 139\n",
      "0.033997853370124176 0.7521122738333662 1\n",
      "epoch: 140\n",
      "0.13841807335961676 0.8571940504638375 1\n",
      "epoch: 141\n",
      "0.045458761790996505 0.012862241253519167 0\n",
      "epoch: 142\n",
      "1.4273524827340225 0.2747436474343241 0\n",
      "epoch: 143\n",
      "1.2239484215232324 0.765311039693269 1\n",
      "epoch: 144\n",
      "0.2884252383338435 0.6321724385631594 1\n",
      "epoch: 145\n",
      "0.17761319504882067 0.5202136151574066 0\n",
      "epoch: 146\n",
      "0.681890465159654 0.05964729279837511 0\n",
      "epoch: 147\n",
      "0.7938421204976294 0.828856871735303 1\n",
      "epoch: 148\n",
      "0.12294015625946031 0.9538693039306844 1\n",
      "epoch: 149\n",
      "0.23625233217512687 0.7894930461338068 1\n",
      "epoch: 150\n",
      "0.36894933748124004 0.2988297423188937 1\n",
      "epoch: 151\n",
      "0.18658298789580385 0.7081566314834217 1\n",
      "epoch: 152\n",
      "0.08518529761295213 0.6402063285449604 1\n",
      "epoch: 153\n",
      "0.05990348730313144 0.8788072296605567 1\n",
      "epoch: 154\n",
      "0.16119949332210126 0.38198522432990084 1\n",
      "epoch: 155\n",
      "2.100782681644091 0.3639616032548099 1\n",
      "epoch: 156\n",
      "2.1521539807357613 0.9457945458046078 1\n",
      "epoch: 157\n",
      "0.07013584549008556 0.05811408062174905 0\n",
      "epoch: 158\n",
      "0.04175010734491025 0.5250504923235486 1\n",
      "epoch: 159\n",
      "0.19203781079602322 0.04473210905611856 0\n",
      "epoch: 160\n",
      "0.1495150241993315 0.20081279526617773 0\n",
      "epoch: 161\n",
      "0.21046245524416918 0.7641895771681331 1\n",
      "epoch: 162\n",
      "0.02235798678430001 0.7828841727499463 1\n",
      "epoch: 163\n",
      "0.1688084399534091 0.3706196595539168 0\n",
      "epoch: 164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23062126780632752 0.8942505255597423 1\n",
      "epoch: 165\n",
      "0.20216371502147013 0.27844249796378423 0\n",
      "epoch: 166\n",
      "0.584103863196674 0.4038612502708753 1\n",
      "epoch: 167\n",
      "0.4265949433793139 0.27880518442676144 0\n",
      "epoch: 168\n",
      "0.0911212745679677 0.05728715562243437 0\n",
      "epoch: 169\n",
      "0.44355304263922335 0.7589531325254785 1\n",
      "epoch: 170\n",
      "0.4317147044137073 0.12637835698495292 0\n",
      "epoch: 171\n",
      "0.04825422563055781 0.4829457552080905 0\n",
      "epoch: 172\n",
      "0.027565995264581034 0.33450541828822866 0\n",
      "epoch: 173\n",
      "0.8629590405183762 0.18640807673167326 0\n",
      "epoch: 174\n",
      "0.8770983495122664 0.8126713402960335 1\n",
      "epoch: 175\n",
      "0.08245685694976146 0.3856124350923116 0\n",
      "epoch: 176\n",
      "0.057316024623560224 0.5734999314085114 1\n",
      "epoch: 177\n",
      "0.06202419352814559 0.710162725627711 1\n",
      "epoch: 178\n",
      "0.40305351212452933 0.17387414214149985 0\n",
      "epoch: 179\n",
      "0.4224512849702933 0.12688201616429856 0\n",
      "epoch: 180\n",
      "0.17870207132887117 0.390432603653045 0\n",
      "epoch: 181\n",
      "0.13595754030825447 0.2986861093785325 0\n",
      "epoch: 182\n",
      "0.19760476109968295 0.7779294895777163 1\n",
      "epoch: 183\n",
      "0.19247816797235373 0.4095536375999463 0\n",
      "epoch: 184\n",
      "0.24575877220411257 0.7939100529624936 1\n",
      "epoch: 185\n",
      "0.21469404233153 0.3171017837693951 0\n",
      "epoch: 186\n",
      "0.009555774818863938 0.29461621749973493 0\n",
      "epoch: 187\n",
      "0.07916048374931961 0.7083482920586437 1\n",
      "epoch: 188\n",
      "0.014627655121330463 0.292745099482906 0\n",
      "epoch: 189\n",
      "0.03248053691254427 0.1905682493693022 0\n",
      "epoch: 190\n",
      "0.009901962665708197 0.28224188360283214 0\n",
      "epoch: 191\n",
      "0.01624767201508348 0.9833941796672907 1\n",
      "epoch: 192\n",
      "0.0040759320548886535 0.23157662845087215 0\n",
      "epoch: 193\n",
      "0.008142533618070047 0.1214628506972166 0\n",
      "epoch: 194\n",
      "0.005091746026550936 0.8231068810201634 1\n",
      "epoch: 195\n",
      "0.04331451698806177 0.21137898972910169 0\n",
      "epoch: 196\n",
      "0.02423965745890655 0.13109838695387324 0\n",
      "epoch: 197\n",
      "0.016104544318068292 0.6935109164141776 1\n",
      "epoch: 198\n",
      "0.04906480270688007 0.0451725331246766 0\n",
      "epoch: 199\n",
      "0.045778307584328104 0.624786160688719 1\n",
      "epoch: 200\n",
      "0.00579199851517842 0.8003536851012677 1\n",
      "epoch: 201\n",
      "0.08031815390563679 0.6089766318061234 0\n",
      "epoch: 202\n",
      "0.03813485663749816 0.15961736825607842 0\n",
      "epoch: 203\n",
      "0.06257776501388435 0.1681538604530602 0\n",
      "epoch: 204\n",
      "0.07222744207467713 0.54939291693687 1\n",
      "epoch: 205\n",
      "0.03721806759949686 0.9261630378294984 1\n",
      "epoch: 206\n",
      "0.018622057686798144 0.9301762989200267 1\n",
      "epoch: 207\n",
      "0.0037513461368234857 0.40394893980882746 0\n",
      "epoch: 208\n",
      "0.008269482363971292 0.707465860590703 1\n",
      "epoch: 209\n",
      "0.010034989637574654 0.21781705463871914 0\n",
      "epoch: 210\n",
      "0.009917259660596756 0.6938312904915885 1\n",
      "epoch: 211\n",
      "0.008089644540973495 0.8310733739495947 1\n",
      "epoch: 212\n",
      "0.045655351246864484 0.6610954512819116 1\n",
      "epoch: 213\n",
      "0.01892881007699998 0.1457247505875111 0\n",
      "epoch: 214\n",
      "0.009695095590245728 0.3637993598108694 0\n",
      "epoch: 215\n",
      "0.028969612251785293 0.7988448866976702 1\n",
      "epoch: 216\n",
      "0.012239872492045833 0.15692285776456558 0\n",
      "epoch: 217\n",
      "0.008925424565290996 0.26993646768001917 0\n",
      "epoch: 218\n",
      "0.025975463412123645 0.10426990529776206 0\n",
      "epoch: 219\n",
      "0.0023918602406638456 0.0879768093349226 0\n",
      "epoch: 220\n",
      "0.013699727051289301 0.10936611111587781 0\n",
      "epoch: 221\n",
      "0.010705833327847358 0.7523180066718892 1\n",
      "epoch: 222\n",
      "0.004378996684749836 0.7226444018639764 1\n",
      "epoch: 223\n",
      "0.0054120141013527245 0.0191353839385752 0\n",
      "epoch: 224\n",
      "0.00461595597471387 0.2918658409335169 0\n",
      "epoch: 225\n",
      "0.00941103383763675 0.07861919862587287 0\n",
      "epoch: 226\n",
      "0.00463248241464953 0.5241123456006004 1\n",
      "epoch: 227\n",
      "0.003473013058169272 0.1510517360611001 0\n",
      "epoch: 228\n",
      "0.0014645859382653725 0.7017508522470017 1\n",
      "epoch: 229\n",
      "0.016223672922933474 0.7402771007338763 1\n",
      "epoch: 230\n",
      "0.007202833058045144 0.3040482503870434 0\n",
      "epoch: 231\n",
      "0.00920131799284718 0.8597532448610913 1\n",
      "epoch: 232\n",
      "0.004687504653588803 0.13236873136571678 0\n",
      "epoch: 233\n",
      "0.0029837420637477408 0.8415235832459391 1\n",
      "epoch: 234\n",
      "0.006314910419860098 0.31988106749729905 0\n",
      "epoch: 235\n",
      "0.005620274028501626 0.7276629063099489 1\n",
      "epoch: 236\n",
      "0.005233918566318607 0.30250658245958195 0\n",
      "epoch: 237\n",
      "0.0052083625739669515 0.8364166027949165 1\n",
      "epoch: 238\n",
      "0.0031687504442743375 0.43821016770611576 1\n",
      "epoch: 239\n",
      "0.013977886725569988 0.14952502021060324 0\n",
      "epoch: 240\n",
      "0.008532249830068395 0.24379677802181662 0\n",
      "epoch: 241\n",
      "0.002166213445207177 0.8874809915566982 1\n",
      "epoch: 242\n",
      "0.0026327541200998894 0.8794502960514439 1\n",
      "epoch: 243\n",
      "0.0035802461057983237 0.20044243224644026 0\n",
      "epoch: 244\n",
      "[-0.09238036  0.03149136 -0.07540978 ... -0.1166733   0.14265156\n",
      " -0.47190569]\n"
     ]
    }
   ],
   "source": [
    "# try running SGD here\n",
    "weight = SGD(x, y, w, a, lamb)\n",
    "\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d6950886",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(weight, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "698c4f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_x\n",
    "shuffled_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
